{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d01b82e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e459880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9b92aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_llm = GoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "evaluate_llm = GoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "optimizer_llm = GoogleGenerativeAI(model=\"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b756267",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostCreationState(TypedDict):\n",
    "    topic : str\n",
    "    content : str\n",
    "    evaluation : Literal[\"good\", \"bad\"]\n",
    "    feedback : str\n",
    "    iteration: int\n",
    "    max_iterations: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0f51187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state: PostCreationState) -> PostCreationState:\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a funny and clever Twitter/X influencer.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "            Write a short, original, and hilarious tweet on the topic: \"{state['topic']}\".\n",
    "\n",
    "            Rules:\n",
    "            - Do NOT use question-answer format.\n",
    "            - Max 280 characters.\n",
    "            - Use observational humor, irony, sarcasm, or cultural references.\n",
    "            - Think in meme logic, punchlines, or relatable takes.\n",
    "            - Use simple, day to day english.\n",
    "            \"\"\")]\n",
    "    \n",
    "    response = generate_llm.invoke(messages)\n",
    "    state['content'] = response\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e8df95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(state: PostCreationState) -> PostCreationState:\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a social media expert.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "            Evaluate the following tweet for humor and engagement:\n",
    "            \"{state['content']}\"\n",
    "\n",
    "            Rules:\n",
    "            - Rate as \"good\" or \"bad\".\n",
    "            - Provide constructive feedback.\n",
    "            \"\"\")]\n",
    "    \n",
    "    response = evaluate_llm.invoke(messages)\n",
    "    state['evaluation'] = response\n",
    "    state['feedback'] = response\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbeafe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(state: PostCreationState) -> PostCreationState:\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a social media optimization expert.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "            Optimize the following tweet based on feedback:\n",
    "            \"{state['content']}\"\n",
    "            Feedback: \"{state['feedback']}\"\n",
    "\n",
    "            Rules:\n",
    "            - Make it more engaging and humorous.\n",
    "            - Keep it under 280 characters.\n",
    "            \"\"\")]\n",
    "    \n",
    "    response = optimizer_llm.invoke(messages)\n",
    "    state['content'] = response\n",
    "    \n",
    "    if state['evaluation'] == \"good\" or state['iteration'] >= state['max_iterations']:\n",
    "        return END(state)\n",
    "    \n",
    "    state['iteration'] += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9855b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_evaluation(state: PostCreationState):\n",
    "    if state['evaluation'] == \"good\":\n",
    "        return 'exit'\n",
    "    else:\n",
    "        return 'try_again'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73613bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x23bc0aa11d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(PostCreationState)\n",
    "\n",
    "graph.add_node(\"generate\", generate)\n",
    "graph.add_node(\"evaluate\", evaluate)\n",
    "graph.add_node(\"optimize\", optimize)\n",
    "\n",
    "graph.add_edge(START, \"generate\")\n",
    "graph.add_edge(\"generate\", \"evaluate\")\n",
    "\n",
    "graph.add_conditional_edges(\"evaluate\", route_evaluation, {'exit': END, 'try_again': \"optimize\"})\n",
    "graph.add_edge(\"optimize\", \"evaluate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f302a348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000023BC0AA20D0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = graph.compile()\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "272ee5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = {\n",
    "    'topic' : \"AI in bihar\",\n",
    "    'iteration' : 1,\n",
    "    'max_iterations': 3   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "029d17f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ChatGoogleGenerativeAIError",
     "evalue": "Invalid argument provided to Gemini: 400 API Key not found. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API Key not found. Please pass a valid API key.\"\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgument\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:206\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:868\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    867\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mInvalidArgument\u001b[39m: 400 API Key not found. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API Key not found. Please pass a valid API key.\"\n]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result = \u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2844\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2841\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2842\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2844\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2845\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2847\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2848\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2849\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2850\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2851\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2853\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2857\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2534\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2532\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2533\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2534\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2535\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2539\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2541\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2543\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2544\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate\u001b[39m(state: PostCreationState) -> PostCreationState:\n\u001b[32m      2\u001b[39m     messages = [\n\u001b[32m      3\u001b[39m         SystemMessage(content=\u001b[33m\"\u001b[39m\u001b[33mYou are a social media expert.\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      4\u001b[39m         HumanMessage(content=\u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m \u001b[33m            - Provide constructive feedback.\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33m            \u001b[39m\u001b[33m\"\"\"\u001b[39m)]\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     response = \u001b[43mevaluate_llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     state[\u001b[33m'\u001b[39m\u001b[33mevaluation\u001b[39m\u001b[33m'\u001b[39m] = response\n\u001b[32m     15\u001b[39m     state[\u001b[33m'\u001b[39m\u001b[33mfeedback\u001b[39m\u001b[33m'\u001b[39m] = response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:389\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    378\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    380\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    385\u001b[39m     **kwargs: Any,\n\u001b[32m    386\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    387\u001b[39m     config = ensure_config(config)\n\u001b[32m    388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    400\u001b[39m         .text\n\u001b[32m    401\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:766\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    758\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    759\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    763\u001b[39m     **kwargs: Any,\n\u001b[32m    764\u001b[39m ) -> LLMResult:\n\u001b[32m    765\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:971\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    957\u001b[39m     run_managers = [\n\u001b[32m    958\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    959\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    969\u001b[39m         )\n\u001b[32m    970\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n\u001b[32m    979\u001b[39m     run_managers = [\n\u001b[32m    980\u001b[39m         callback_managers[idx].on_llm_start(\n\u001b[32m    981\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    988\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[32m    989\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:792\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    782\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    783\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    788\u001b[39m     **kwargs: Any,\n\u001b[32m    789\u001b[39m ) -> LLMResult:\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    791\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    796\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    799\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    800\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    801\u001b[39m         )\n\u001b[32m    802\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    803\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\langchain_google_genai\\llms.py:114\u001b[39m, in \u001b[36mGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m generations = []\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     chat_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     generations.append(\n\u001b[32m    121\u001b[39m         [\n\u001b[32m    122\u001b[39m             Generation(\n\u001b[32m   (...)\u001b[39m\u001b[32m    130\u001b[39m         ]\n\u001b[32m    131\u001b[39m     )\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1441\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1414\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1415\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1416\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1427\u001b[39m     **kwargs: Any,\n\u001b[32m   1428\u001b[39m ) -> ChatResult:\n\u001b[32m   1429\u001b[39m     request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   1430\u001b[39m         messages,\n\u001b[32m   1431\u001b[39m         stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1439\u001b[39m         **kwargs,\n\u001b[32m   1440\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1441\u001b[39m     response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1443\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1445\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1446\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1447\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:231\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    222\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    224\u001b[39m params = (\n\u001b[32m    225\u001b[39m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[32m    226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (request := kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[32m    230\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\langGraph-learning\\myenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:218\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.InvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[32m    219\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    220\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m: Invalid argument provided to Gemini: 400 API Key not found. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API Key not found. Please pass a valid API key.\"\n]",
      "During task with name 'evaluate' and id 'dc4525bd-b844-6a76-cf36-d5f6cf974f94'"
     ]
    }
   ],
   "source": [
    "result = workflow.invoke(init_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e140521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
